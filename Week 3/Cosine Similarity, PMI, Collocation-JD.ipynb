{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Count Vectorization - One Hot Encoding and other Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T03:27:26.016344Z",
     "start_time": "2021-04-07T03:27:24.601867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1901</td>\n",
       "      <td>Kansas Saloon Smashers</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...</td>\n",
       "      <td>A bartender is working at a saloon, serving dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>Love by the Light of the Moon</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Love_by_the_Ligh...</td>\n",
       "      <td>The moon, painted with a smiling face hangs ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1901</td>\n",
       "      <td>The Martyred Presidents</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Martyred_Pre...</td>\n",
       "      <td>The film, just over a minute long, is composed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1901</td>\n",
       "      <td>Terrible Teddy, the Grizzly King</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Terrible_Teddy,_...</td>\n",
       "      <td>Lasting just 61 seconds and consisting of two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>Jack and the Beanstalk</td>\n",
       "      <td>American</td>\n",
       "      <td>George S. Fleming, Edwin S. Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jack_and_the_Bea...</td>\n",
       "      <td>The earliest known adaptation of the classic f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>1929</td>\n",
       "      <td>Our Modern Maidens</td>\n",
       "      <td>American</td>\n",
       "      <td>Jack Conway</td>\n",
       "      <td>Joan Crawford, Douglas Fairbanks Jr.</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Our_Modern_Maidens</td>\n",
       "      <td>Heiress Billie Brown (Crawford), is engaged to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>1929</td>\n",
       "      <td>The Pagan</td>\n",
       "      <td>American</td>\n",
       "      <td>W.S. Van Dyke</td>\n",
       "      <td>Ramon Novarro, Renee Adoree, Donald Crisp</td>\n",
       "      <td>romance</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Pagan</td>\n",
       "      <td>Trader Henry Slater (Donald Crisp) stops at a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>1929</td>\n",
       "      <td>Paris</td>\n",
       "      <td>American</td>\n",
       "      <td>Clarence G. Badger</td>\n",
       "      <td>Irene Bordoni, Jack Buchanan</td>\n",
       "      <td>musical comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Paris_(1929_film)</td>\n",
       "      <td>Irène Bordoni is cast as Vivienne Rolland, a P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>1929</td>\n",
       "      <td>Queen Kelly</td>\n",
       "      <td>American</td>\n",
       "      <td>Erich von Stroheim</td>\n",
       "      <td>Gloria Swanson, Walter Byron</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Queen_Kelly</td>\n",
       "      <td>Prince Wolfram (Byron) is the betrothed of mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>1929</td>\n",
       "      <td>Queen of the Night Clubs</td>\n",
       "      <td>American</td>\n",
       "      <td>Bryan Foy</td>\n",
       "      <td>Texas Guinan, Lila Lee</td>\n",
       "      <td>musical</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Queen_of_the_Nig...</td>\n",
       "      <td>After working as a hostess for Nick and Andy, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>836 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Release Year                             Title Origin/Ethnicity  \\\n",
       "0            1901            Kansas Saloon Smashers         American   \n",
       "1            1901     Love by the Light of the Moon         American   \n",
       "2            1901           The Martyred Presidents         American   \n",
       "3            1901  Terrible Teddy, the Grizzly King         American   \n",
       "4            1902            Jack and the Beanstalk         American   \n",
       "..            ...                               ...              ...   \n",
       "831          1929                Our Modern Maidens         American   \n",
       "832          1929                         The Pagan         American   \n",
       "833          1929                             Paris         American   \n",
       "834          1929                       Queen Kelly         American   \n",
       "835          1929          Queen of the Night Clubs         American   \n",
       "\n",
       "                               Director  \\\n",
       "0                               Unknown   \n",
       "1                               Unknown   \n",
       "2                               Unknown   \n",
       "3                               Unknown   \n",
       "4    George S. Fleming, Edwin S. Porter   \n",
       "..                                  ...   \n",
       "831                         Jack Conway   \n",
       "832                       W.S. Van Dyke   \n",
       "833                  Clarence G. Badger   \n",
       "834                  Erich von Stroheim   \n",
       "835                           Bryan Foy   \n",
       "\n",
       "                                          Cast           Genre  \\\n",
       "0                                          NaN         unknown   \n",
       "1                                          NaN         unknown   \n",
       "2                                          NaN         unknown   \n",
       "3                                          NaN         unknown   \n",
       "4                                          NaN         unknown   \n",
       "..                                         ...             ...   \n",
       "831       Joan Crawford, Douglas Fairbanks Jr.           drama   \n",
       "832  Ramon Novarro, Renee Adoree, Donald Crisp         romance   \n",
       "833               Irene Bordoni, Jack Buchanan  musical comedy   \n",
       "834               Gloria Swanson, Walter Byron           drama   \n",
       "835                     Texas Guinan, Lila Lee         musical   \n",
       "\n",
       "                                             Wiki Page  \\\n",
       "0    https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...   \n",
       "1    https://en.wikipedia.org/wiki/Love_by_the_Ligh...   \n",
       "2    https://en.wikipedia.org/wiki/The_Martyred_Pre...   \n",
       "3    https://en.wikipedia.org/wiki/Terrible_Teddy,_...   \n",
       "4    https://en.wikipedia.org/wiki/Jack_and_the_Bea...   \n",
       "..                                                 ...   \n",
       "831   https://en.wikipedia.org/wiki/Our_Modern_Maidens   \n",
       "832            https://en.wikipedia.org/wiki/The_Pagan   \n",
       "833    https://en.wikipedia.org/wiki/Paris_(1929_film)   \n",
       "834          https://en.wikipedia.org/wiki/Queen_Kelly   \n",
       "835  https://en.wikipedia.org/wiki/Queen_of_the_Nig...   \n",
       "\n",
       "                                                  Plot  \n",
       "0    A bartender is working at a saloon, serving dr...  \n",
       "1    The moon, painted with a smiling face hangs ov...  \n",
       "2    The film, just over a minute long, is composed...  \n",
       "3    Lasting just 61 seconds and consisting of two ...  \n",
       "4    The earliest known adaptation of the classic f...  \n",
       "..                                                 ...  \n",
       "831  Heiress Billie Brown (Crawford), is engaged to...  \n",
       "832  Trader Henry Slater (Donald Crisp) stops at a ...  \n",
       "833  Irène Bordoni is cast as Vivienne Rolland, a P...  \n",
       "834  Prince Wolfram (Byron) is the betrothed of mad...  \n",
       "835  After working as a hostess for Nick and Andy, ...  \n",
       "\n",
       "[836 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "plots_df = pd.read_csv(\"movie_plots.csv\")\n",
    "\n",
    "# filter only for American movies\n",
    "plots_df = plots_df[plots_df[\"Origin/Ethnicity\"] == \"American\"]\n",
    "plots_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T03:28:45.116253Z",
     "start_time": "2021-04-07T03:28:45.110293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.feature_extraction.text.CountVectorizer'>\n",
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n"
     ]
    }
   ],
   "source": [
    "vectorizers=[CountVectorizer, TfidfVectorizer]\n",
    "for vectorizer in vectorizers:\n",
    "    # see below\n",
    "    print(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T03:47:55.444231Z",
     "start_time": "2021-03-31T03:47:55.181892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe is (836, 14807)\n",
      "Total number of occurences: 175010\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>11</th>\n",
       "      <th>119</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>1373</th>\n",
       "      <th>...</th>\n",
       "      <th>zilah</th>\n",
       "      <th>zinderneuf</th>\n",
       "      <th>zola</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoological</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zulus</th>\n",
       "      <th>álvarez</th>\n",
       "      <th>émile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 14807 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  10  100  1000  11  119  12  13  1373  ...  zilah  zinderneuf  \\\n",
       "0   0    0   0    0     0   0    0   0   0     0  ...      0           0   \n",
       "1   0    0   0    0     0   0    0   0   0     0  ...      0           0   \n",
       "2   0    0   0    0     0   0    0   0   0     0  ...      0           0   \n",
       "3   0    0   0    0     0   0    0   0   0     0  ...      0           0   \n",
       "4   0    0   0    0     0   0    0   0   0     0  ...      0           0   \n",
       "\n",
       "   zola  zone  zones  zoological  zorro  zulus  álvarez  émile  \n",
       "0     0     0      0           0      0      0        0      0  \n",
       "1     0     0      0           0      0      0        0      0  \n",
       "2     0     0      0           0      0      0        0      0  \n",
       "3     0     0      0           0      0      0        0      0  \n",
       "4     0     0      0           0      0      0        0      0  \n",
       "\n",
       "[5 rows x 14807 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # traditional CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# # use English stopwords, and use one-hot encoding\n",
    "#vectorizer = CountVectorizer(stop_words=\"english\", binary=True)\n",
    "\n",
    "# use English stopwords, and use one-hot encoding, and the word must appear in at least two of the movie plots\n",
    "#vectorizer = CountVectorizer(stop_words=\"english\", binary=True, min_df=0.05) \n",
    "\n",
    "# use English stopwords, and use one-hot encoding, and the word must appear in at least two of the movie plots\n",
    "# and keep only the top 200\n",
    "#vectorizer = CountVectorizer(stop_words=\"english\", binary=True, min_df=2, max_features=200) \n",
    "\n",
    "# use English stopwords, and use one-hot encoding, and the word must appear in at least two of the movie plots\n",
    "# and keep only the top 200\n",
    "#vectorizer = CountVectorizer(stop_words=\"english\", binary=True, min_df=2, max_features=200) \n",
    "\n",
    "X = vectorizer.fit_transform(plots_df[\"Plot\"])\n",
    "\n",
    "vectorized_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "print(f\"Shape of dataframe is {vectorized_df.shape}\")\n",
    "print(f\"Total number of occurences: {vectorized_df.sum().sum()}\")\n",
    "#print(f\"Word counts: {vectorized_df.sum()}\")\n",
    "vectorized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T03:48:50.938817Z",
     "start_time": "2021-03-31T03:48:50.618396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe is (836, 14526)\n",
      "Total number of occurences: 69204\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>11</th>\n",
       "      <th>119</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>1373</th>\n",
       "      <th>...</th>\n",
       "      <th>zilah</th>\n",
       "      <th>zinderneuf</th>\n",
       "      <th>zola</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoological</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zulus</th>\n",
       "      <th>álvarez</th>\n",
       "      <th>émile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 14526 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  10  100  1000  11  119  12  13  1373  ...  zilah  zinderneuf  \\\n",
       "0   0    0   0    0     0   0    0   0   0     0  ...      0           0   \n",
       "1   0    0   0    0     0   0    0   0   0     0  ...      0           0   \n",
       "2   0    0   0    0     0   0    0   0   0     0  ...      0           0   \n",
       "3   0    0   0    0     0   0    0   0   0     0  ...      0           0   \n",
       "4   0    0   0    0     0   0    0   0   0     0  ...      0           0   \n",
       "\n",
       "   zola  zone  zones  zoological  zorro  zulus  álvarez  émile  \n",
       "0     0     0      0           0      0      0        0      0  \n",
       "1     0     0      0           0      0      0        0      0  \n",
       "2     0     0      0           0      0      0        0      0  \n",
       "3     0     0      0           0      0      0        0      0  \n",
       "4     0     0      0           0      0      0        0      0  \n",
       "\n",
       "[5 rows x 14526 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# # use English stopwords, and use one-hot encoding\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", binary=True)\n",
    "\n",
    "# use English stopwords, and use one-hot encoding, and the word must appear in at least two of the movie plots\n",
    "#vectorizer = CountVectorizer(stop_words=\"english\", binary=True, min_df=0.05) \n",
    "\n",
    "# use English stopwords, and use one-hot encoding, and the word must appear in at least two of the movie plots\n",
    "# and keep only the top 200\n",
    "#vectorizer = CountVectorizer(stop_words=\"english\", binary=True, min_df=2, max_features=200) \n",
    "\n",
    "# use English stopwords, and use one-hot encoding, and the word must appear in at least two of the movie plots\n",
    "# and keep only the top 200\n",
    "#vectorizer = CountVectorizer(stop_words=\"english\", binary=True, min_df=2, max_features=200) \n",
    "\n",
    "X = vectorizer.fit_transform(plots_df[\"Plot\"])\n",
    "\n",
    "vectorized_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "print(f\"Shape of dataframe is {vectorized_df.shape}\")\n",
    "print(f\"Total number of occurences: {vectorized_df.sum().sum()}\")\n",
    "#print(f\"Word counts: {vectorized_df.sum()}\")\n",
    "vectorized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T03:49:54.715936Z",
     "start_time": "2021-03-31T03:49:54.469075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe is (836, 213)\n",
      "Total number of occurences: 17776\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>accepts</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>agrees</th>\n",
       "      <th>american</th>\n",
       "      <th>appears</th>\n",
       "      <th>arrested</th>\n",
       "      <th>arrive</th>\n",
       "      <th>arrives</th>\n",
       "      <th>asks</th>\n",
       "      <th>...</th>\n",
       "      <th>william</th>\n",
       "      <th>wins</th>\n",
       "      <th>woman</th>\n",
       "      <th>women</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  accepts  accidentally  agrees  american  appears  arrested  arrive  \\\n",
       "0     0        0             0       0         0        0         0       0   \n",
       "1     0        0             0       0         0        0         0       0   \n",
       "2     0        0             0       0         0        0         0       0   \n",
       "3     0        0             0       0         0        1         0       0   \n",
       "4     1        0             0       0         0        0         0       0   \n",
       "\n",
       "   arrives  asks  ...  william  wins  woman  women  work  world  year  years  \\\n",
       "0        0     0  ...        0     0      0      0     0      0     0      0   \n",
       "1        0     0  ...        0     0      1      0     0      0     0      0   \n",
       "2        0     0  ...        1     0      0      0     0      0     0      0   \n",
       "3        0     0  ...        0     0      0      0     0      0     0      0   \n",
       "4        0     0  ...        0     0      0      0     0      0     0      0   \n",
       "\n",
       "   york  young  \n",
       "0     0      0  \n",
       "1     0      1  \n",
       "2     0      0  \n",
       "3     0      0  \n",
       "4     0      0  \n",
       "\n",
       "[5 rows x 213 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# # use English stopwords, and use one-hot encoding\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", binary=True)\n",
    "\n",
    "# use English stopwords, and use one-hot encoding, and the word must appear in at least 5% of the movie plots\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", binary=True, min_df=0.05) \n",
    "\n",
    "# use English stopwords, and use one-hot encoding, and the word must appear in at least two of the movie plots\n",
    "# and keep only the top 200\n",
    "#vectorizer = CountVectorizer(stop_words=\"english\", binary=True, min_df=2, max_features=200) \n",
    "\n",
    "# use English stopwords, and use one-hot encoding, and the word must appear in at least two of the movie plots\n",
    "# and keep only the top 200\n",
    "#vectorizer = CountVectorizer(stop_words=\"english\", binary=True, min_df=2, max_features=200) \n",
    "\n",
    "X = vectorizer.fit_transform(plots_df[\"Plot\"])\n",
    "\n",
    "vectorized_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "print(f\"Shape of dataframe is {vectorized_df.shape}\")\n",
    "print(f\"Total number of occurences: {vectorized_df.sum().sum()}\")\n",
    "#print(f\"Word counts: {vectorized_df.sum()}\")\n",
    "vectorized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T03:51:56.227160Z",
     "start_time": "2021-03-31T03:51:56.059380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe is (836, 1485)\n",
      "Total number of occurences: 52760\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandons</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>absence</th>\n",
       "      <th>accept</th>\n",
       "      <th>accepts</th>\n",
       "      <th>accident</th>\n",
       "      <th>...</th>\n",
       "      <th>writes</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>yacht</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1485 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  10  abandoned  abandons  able  aboard  absence  accept  accepts  \\\n",
       "0    0   0          0         0     0       0        0       0        0   \n",
       "1    0   0          0         0     0       0        0       0        0   \n",
       "2    0   0          0         0     0       0        0       0        0   \n",
       "3    0   0          0         0     0       0        0       0        0   \n",
       "4    0   0          0         0     1       0        0       0        0   \n",
       "\n",
       "   accident  ...  writes  written  wrong  yacht  year  years  york  young  \\\n",
       "0         0  ...       0        0      0      0     0      0     0      0   \n",
       "1         0  ...       0        0      0      0     0      0     0      1   \n",
       "2         0  ...       0        0      0      0     0      0     0      0   \n",
       "3         0  ...       0        0      0      0     0      0     0      0   \n",
       "4         0  ...       0        0      0      0     0      0     0      0   \n",
       "\n",
       "   younger  youth  \n",
       "0        0      0  \n",
       "1        0      0  \n",
       "2        0      0  \n",
       "3        0      0  \n",
       "4        0      0  \n",
       "\n",
       "[5 rows x 1485 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# # use English stopwords, and use one-hot encoding\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", binary=True)\n",
    "\n",
    "# use English stopwords, and use one-hot encoding, and the word must appear in at least 5% of the movie plots\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", binary=True, min_df=0.02) \n",
    "\n",
    "# use English stopwords, and use one-hot encoding, and the word must appear in at least two of the movie plots\n",
    "# and keep only the top 200\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", min_df=10)#, max_features=200) \n",
    "\n",
    "# use English stopwords, and use one-hot encoding, and the word must appear in at least two of the movie plots\n",
    "# and keep only the top 200\n",
    "#vectorizer = CountVectorizer(stop_words=\"english\", binary=True, min_df=2, max_features=200) \n",
    "\n",
    "X = vectorizer.fit_transform(plots_df[\"Plot\"])\n",
    "\n",
    "vectorized_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "print(f\"Shape of dataframe is {vectorized_df.shape}\")\n",
    "print(f\"Total number of occurences: {vectorized_df.sum().sum()}\")\n",
    "#print(f\"Word counts: {vectorized_df.sum()}\")\n",
    "vectorized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T03:53:01.713836Z",
     "start_time": "2021-03-31T03:53:01.702866Z"
    }
   },
   "outputs": [],
   "source": [
    "# can create a number toke (takes all numbers)\n",
    "# min_df = 0.05 means it must appear in 5% of docs, if number is above 1 (it translates to number of instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T03:53:09.664559Z",
     "start_time": "2021-03-31T03:53:09.486911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe is (836, 200)\n",
      "Total number of occurences: 17224\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>accepts</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>agrees</th>\n",
       "      <th>american</th>\n",
       "      <th>appears</th>\n",
       "      <th>arrested</th>\n",
       "      <th>arrives</th>\n",
       "      <th>asks</th>\n",
       "      <th>attempt</th>\n",
       "      <th>...</th>\n",
       "      <th>wife</th>\n",
       "      <th>william</th>\n",
       "      <th>wins</th>\n",
       "      <th>woman</th>\n",
       "      <th>women</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  accepts  accidentally  agrees  american  appears  arrested  arrives  \\\n",
       "0     0        0             0       0         0        0         0        0   \n",
       "1     0        0             0       0         0        0         0        0   \n",
       "2     0        0             0       0         0        0         0        0   \n",
       "3     0        0             0       0         0        1         0        0   \n",
       "4     1        0             0       0         0        0         0        0   \n",
       "\n",
       "   asks  attempt  ...  wife  william  wins  woman  women  work  world  years  \\\n",
       "0     0        0  ...     0        0     0      0      0     0      0      0   \n",
       "1     0        0  ...     0        0     0      1      0     0      0      0   \n",
       "2     0        0  ...     0        1     0      0      0     0      0      0   \n",
       "3     0        0  ...     0        0     0      0      0     0      0      0   \n",
       "4     0        0  ...     0        0     0      0      0     0      0      0   \n",
       "\n",
       "   york  young  \n",
       "0     0      0  \n",
       "1     0      1  \n",
       "2     0      0  \n",
       "3     0      0  \n",
       "4     0      0  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# # use English stopwords, and use one-hot encoding\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", binary=True)\n",
    "\n",
    "# use English stopwords, and use one-hot encoding, and the word must appear in at least 5% of the movie plots\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", binary=True, min_df=0.02) \n",
    "\n",
    "# use English stopwords, and use one-hot encoding, and the word must appear in at least two of the movie plots\n",
    "# and keep only the top 200\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", min_df=10)#, max_features=200) \n",
    "\n",
    "# use English stopwords, and use one-hot encoding, and the word must appear in at least two of the movie plots\n",
    "# and keep only the top 200\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", binary=True, min_df=2, max_features=200) \n",
    "\n",
    "X = vectorizer.fit_transform(plots_df[\"Plot\"])\n",
    "\n",
    "vectorized_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "print(f\"Shape of dataframe is {vectorized_df.shape}\")\n",
    "print(f\"Total number of occurences: {vectorized_df.sum().sum()}\")\n",
    "#print(f\"Word counts: {vectorized_df.sum()}\")\n",
    "vectorized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T04:15:38.907700Z",
     "start_time": "2021-03-31T04:15:38.539040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe is (836, 200)\n",
      "Total number of occurences: 2255\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10 000</th>\n",
       "      <th>aboard ship</th>\n",
       "      <th>abraham lincoln</th>\n",
       "      <th>accused murder</th>\n",
       "      <th>agrees marry</th>\n",
       "      <th>alice terry</th>\n",
       "      <th>american civil</th>\n",
       "      <th>asks marry</th>\n",
       "      <th>aunt polly</th>\n",
       "      <th>beautiful young</th>\n",
       "      <th>...</th>\n",
       "      <th>years pass</th>\n",
       "      <th>york city</th>\n",
       "      <th>young boy</th>\n",
       "      <th>young couple</th>\n",
       "      <th>young girl</th>\n",
       "      <th>young lady</th>\n",
       "      <th>young man</th>\n",
       "      <th>young men</th>\n",
       "      <th>young woman</th>\n",
       "      <th>younger brother</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   10 000  aboard ship  abraham lincoln  accused murder  agrees marry  \\\n",
       "0       0            0                0               0             0   \n",
       "1       0            0                0               0             0   \n",
       "2       0            0                1               0             0   \n",
       "3       0            0                0               0             0   \n",
       "4       0            0                0               0             0   \n",
       "\n",
       "   alice terry  american civil  asks marry  aunt polly  beautiful young  ...  \\\n",
       "0            0               0           0           0                0  ...   \n",
       "1            0               0           0           0                0  ...   \n",
       "2            0               0           0           0                0  ...   \n",
       "3            0               0           0           0                0  ...   \n",
       "4            0               0           0           0                0  ...   \n",
       "\n",
       "   years pass  york city  young boy  young couple  young girl  young lady  \\\n",
       "0           0          0          0             0           0           0   \n",
       "1           0          0          0             1           0           0   \n",
       "2           0          0          0             0           0           0   \n",
       "3           0          0          0             0           0           0   \n",
       "4           0          0          0             0           0           0   \n",
       "\n",
       "   young man  young men  young woman  younger brother  \n",
       "0          0          0            0                0  \n",
       "1          0          0            0                0  \n",
       "2          0          0            0                0  \n",
       "3          0          0            0                0  \n",
       "4          0          0            0                0  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# # use English stopwords, and use one-hot encoding\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", binary=True)\n",
    "\n",
    "# use English stopwords, and use one-hot encoding, and the word must appear in at least 5% of the movie plots\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", binary=True, min_df=0.02) \n",
    "\n",
    "# use English stopwords, and use one-hot encoding, and the word must appear in at least two of the movie plots\n",
    "# and keep only the top 200\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", min_df=10)#, max_features=200) \n",
    "\n",
    "# use English stopwords, and use one-hot encoding, and the word must appear in at least two of the movie plots\n",
    "# and keep only the top 200\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2),stop_words=\"english\", min_df=2, max_features=200) \n",
    "\n",
    "X = vectorizer.fit_transform(plots_df[\"Plot\"])\n",
    "\n",
    "vectorized_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "print(f\"Shape of dataframe is {vectorized_df.shape}\")\n",
    "print(f\"Total number of occurences: {vectorized_df.sum().sum()}\")\n",
    "#print(f\"Word counts: {vectorized_df.sum()}\")\n",
    "vectorized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see n_gram above (2,2) - pair of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity Example\n",
    "\n",
    "### Intro to Algorithmic Marketing:\n",
    "![alt text](images/cos-sim-textbook1.png \"Logo Title Text 1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Magnitude of a Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T05:44:19.796771Z",
     "start_time": "2021-04-02T05:44:19.783116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First approach: 3.7416573867739413\n",
      "Second approach: 3.7416573867739413\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "def magnitude(x): \n",
    "    return math.sqrt(sum(i**2 for i in x))\n",
    "\n",
    "vectorA = [0,3,1,2]\n",
    "\n",
    "print(f\"First approach: {magnitude(vectorA)}\")\n",
    "print(f\"Second approach: {np.linalg.norm(vectorA)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointwise Mutual Information\n",
    "\n",
    "It's important to identify a **context window** when analyzing co-occurence. In the image below, the context window size is 4 (2 tokens to either side of the target word):\n",
    "\n",
    "![alt text](images/context_window.png \"Logo Title Text 1\")\n",
    "\n",
    "For the purposes of the next section, we'll define the **entire document as the context window.**\n",
    "\n",
    "Pointwise mutual information measures the ratio between the **joint probability of two events happening** with the probabilities of the two events happening, assuming they are independent. It can be defined with the following equation:\n",
    "\n",
    "$$\n",
    "PMI_{A,B} = log\\frac{p(A,B)}{p(A)p(B)}\n",
    "$$\n",
    "\n",
    "Remember that when two events are independent, $P(i,j) = P(i)P(j)$. Using PMI to just a raw word count is often preferable because very common words have extreme skew (\"the\" and \"of\" will co-occur frequently in the same  )\n",
    "\n",
    "```python\n",
    "import math\n",
    "def pmi(tokenA, tokenB, documents, word_counts):\n",
    "    \n",
    "    # word_counts[token_A] => number of times tokenA appears in the documents\n",
    "    # float(len(documents)) => number of documents\n",
    "    # bigram_freq => a dictionary of the number of times tokenA and tokenB are in the same document together\n",
    "    \n",
    "    prob_A = word_counts[tokenA] / float(len(documents))\n",
    "    prob_B = word_counts[tokenB] / float(len(documents))\n",
    "    prob_A_B = bigram_freq[\" \".join([tokenA, tokenB])] / float(len(documents))\n",
    "    return math.log(prob_A_B/float(prob_A*prob_B),2) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocation\n",
    "\n",
    "Many times, in previous homeworks, we've had to manually try to find phrases that belong together. For example, `New York City`.\n",
    "\n",
    "From [nltk.org](http://www.nltk.org/howto/collocations.html), **collocation** can be defined as\n",
    "\n",
    "> expressions of multiple words which commonly co-occur together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['New','York','City'] ---> ['NEW_YORK_CITY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english') + [\".\",'.', \",\",\":\", \"''\", \"'s\", \"'\", \"``\", \"(\", \")\", \"-\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "articles = [f\"bbcsport/football/00{i}.txt\" for i in range(1,10)]\n",
    "\n",
    "for article in articles:\n",
    "    article = open(article) # open each sports article\n",
    "    for line in article.readlines():\n",
    "        line = line.replace(\"\\n\", \"\") # replace the new line escape character\n",
    "        if len(line) > 0: # if the line is not empty, process it\n",
    "            line = [lemmatizer.lemmatize(token) for token in word_tokenize(line)] \n",
    "            documents.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_documents = []\n",
    "for doc in documents:\n",
    "    new_document = []\n",
    "    for word in doc:\n",
    "        if word.strip().lower() not in stopwords:\n",
    "            new_document.append(word)\n",
    "    new_documents.append(new_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collocation_finder = BigramCollocationFinder.from_documents(new_documents)\n",
    "measures = BigramAssocMeasures()\n",
    "\n",
    "collocation_finder.nbest(measures.raw_freq, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF (for a term, for a specific document)\n",
    "# TF = looks within a single document\n",
    "# IDF = looks at all the documents\n",
    "# rare words have a very high IDF score\n",
    "# \"the\" will have low IDF scores, \"McDonald's\" will have high IDF scores\n",
    "# works better for longer documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency / Inverse Document Frequency\n",
    "\n",
    "\n",
    "## Term Frequency\n",
    "![alt text](images/tf-idf1.png \"Term Frequency\")\n",
    "\n",
    "## Inverse Document Frequency\n",
    "![alt text](images/tf-idf2.png \"Inverse Document Frequency\")\n",
    "\n",
    "### Example Calculation\n",
    "\n",
    "![alt text](images/tf-idf4.png \"Example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so far just unigrams\n",
    "# but we may want phrases \"ngrams\" - skinny jeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Scikit-Learn to Generate TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T04:17:02.154083Z",
     "start_time": "2021-03-31T04:17:02.111202Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mcdonalds-yelp-negative-reviews.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T04:17:44.710658Z",
     "start_time": "2021-03-31T04:17:43.743000Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(3,4),\n",
    "                             token_pattern=r'\\b[a-zA-Z]{3,}\\b',\n",
    "                             max_df=0.4, stop_words=stopwords.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T04:18:11.517231Z",
     "start_time": "2021-03-31T04:18:10.725358Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19258\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:391: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['baiknya', 'berkali', 'kali', 'kurangnya', 'mata', 'olah', 'printr', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"mcdonalds-yelp-negative-reviews.csv\", encoding=\"latin1\")\n",
    "corpus = list(df[\"review\"].values)\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "terms = vectorizer.get_feature_names()\n",
    "tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T04:19:45.258371Z",
     "start_time": "2021-03-31T04:19:45.225460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaaaaaaahhhhhhhhhhh still feel',\n",
       " 'aaaaaaaahhhhhhhhhhh still feel situation',\n",
       " 'abbreviated menu worthy',\n",
       " 'abbreviated menu worthy mcdonald',\n",
       " 'abc kitchen numerous',\n",
       " 'abc kitchen numerous times',\n",
       " 'ability answer questions',\n",
       " 'ability answer questions menu',\n",
       " 'ability innovate launching',\n",
       " 'ability innovate launching products',\n",
       " 'ability specific location',\n",
       " 'ability specific location produce',\n",
       " 'able access wifi',\n",
       " 'able access wifi stopping',\n",
       " 'able advance join',\n",
       " 'able advance join main',\n",
       " 'able buy meal',\n",
       " 'able buy meal complain',\n",
       " 'able catch time',\n",
       " 'able catch time wait',\n",
       " 'able collect thoughts',\n",
       " 'able collect thoughts order',\n",
       " 'able convince coupon',\n",
       " 'able convince coupon clearly',\n",
       " 'able convince twins',\n",
       " 'able convince twins decided',\n",
       " 'able escape raised',\n",
       " 'able escape raised drive',\n",
       " 'able exit onto',\n",
       " 'able exit onto kostner',\n",
       " 'able fulfill orders',\n",
       " 'able fulfill orders cashier',\n",
       " 'able get correct',\n",
       " 'able get correct order',\n",
       " 'able get dozen',\n",
       " 'able get dozen cheeseburgers',\n",
       " 'able get shit',\n",
       " 'able get shit together',\n",
       " 'able get straight',\n",
       " 'able get straight time',\n",
       " 'able get wanted',\n",
       " 'able get wanted wanted',\n",
       " 'able keep order',\n",
       " 'able keep order always',\n",
       " 'able make left',\n",
       " 'able make left turn',\n",
       " 'able make usual',\n",
       " 'able make usual shitty',\n",
       " 'able provide products',\n",
       " 'able provide products menu',\n",
       " 'able pull easily',\n",
       " 'able pull easily traffic',\n",
       " 'able put order',\n",
       " 'able put order put',\n",
       " 'able reverse way',\n",
       " 'able reverse way recommendations',\n",
       " 'able stand word',\n",
       " 'able stand word lied',\n",
       " 'able trust mcdonald',\n",
       " 'able trust mcdonald time',\n",
       " 'abode ready dive',\n",
       " 'abode ready dive burger',\n",
       " 'abour order wrong',\n",
       " 'abour order wrong last',\n",
       " 'abrams anywho often',\n",
       " 'abrams anywho often folks',\n",
       " 'abrasive unhelpful attitude',\n",
       " 'absolute best breakfast',\n",
       " 'absolute best breakfast long',\n",
       " 'absolute chaos inside',\n",
       " 'absolute chaos inside reviewers',\n",
       " 'absolute crappiest food',\n",
       " 'absolute crappiest food available',\n",
       " 'absolute joke aubrey',\n",
       " 'absolute joke aubrey manager',\n",
       " 'absolute last time',\n",
       " 'absolute last time ever',\n",
       " 'absolute worst mcdonald',\n",
       " 'absolute worst mcdonald ever',\n",
       " 'absolute worst mcdonalds',\n",
       " 'absolute worst mcdonalds upper',\n",
       " 'absolute worst treat',\n",
       " 'absolute worst treat every',\n",
       " 'absolutely awful always',\n",
       " 'absolutely awful always seems',\n",
       " 'absolutely creepy depending',\n",
       " 'absolutely creepy depending time',\n",
       " 'absolutely defies logic',\n",
       " 'absolutely defies logic yes',\n",
       " 'absolutely despise mcdonalds',\n",
       " 'absolutely despise mcdonalds nice',\n",
       " 'absolutely dread encountering',\n",
       " 'absolutely dread encountering slightly',\n",
       " 'absolutely greeted whatsoever',\n",
       " 'absolutely greeted whatsoever whoever',\n",
       " 'absolutely hate course',\n",
       " 'absolutely hate course late',\n",
       " 'absolutely hate theirservice',\n",
       " 'absolutely hate theirservice girlfriend',\n",
       " 'absolutely horrible last',\n",
       " 'absolutely horrible last times',\n",
       " 'absolutely love mcdonald',\n",
       " 'absolutely love mcdonald sweet',\n",
       " 'absolutely loved get',\n",
       " 'absolutely loved get definitely',\n",
       " 'absolutely must use',\n",
       " 'absolutely must use location',\n",
       " 'absolutely notta saw',\n",
       " 'absolutely notta saw kitchen',\n",
       " 'absolutely option eating',\n",
       " 'absolutely option eating mcdonalds',\n",
       " 'absolutely pretty much',\n",
       " 'absolutely pretty much ate',\n",
       " 'absolutely ridiculous times',\n",
       " 'absolutely ridiculous times today',\n",
       " 'absolutely shocked customer',\n",
       " 'absolutely shocked customer service',\n",
       " 'absolutely shocking wait',\n",
       " 'absolutely shocking wait five',\n",
       " 'absolutely sorriest mistake',\n",
       " 'absolutely sorriest mistake mcdonalds',\n",
       " 'absolutely unproductive add',\n",
       " 'absolutely unproductive add insult',\n",
       " 'absolutely vile disgusting',\n",
       " 'absolutely vile disgusting food',\n",
       " 'absolutely vile ghastly',\n",
       " 'absolutely vile ghastly disgusting',\n",
       " 'absolutely went food',\n",
       " 'absolutely went food window',\n",
       " 'absolutely worst fast',\n",
       " 'absolutely worst fast food',\n",
       " 'absolutely worst mcdonalds',\n",
       " 'absolutely worst mcdonalds rude',\n",
       " 'absolutely worst shameful',\n",
       " 'absolutely worst shameful mcdonald',\n",
       " 'absorb alcohol ingested',\n",
       " 'absorb alcohol ingested manager',\n",
       " 'absurd drive makes',\n",
       " 'absurd drive makes place',\n",
       " 'absurd hard get',\n",
       " 'absurd hard get order',\n",
       " 'absurd saw treated',\n",
       " 'absurd saw treated guest',\n",
       " 'abundance homeless crazy',\n",
       " 'abundance homeless crazy people',\n",
       " 'abundance tweekers crackheads',\n",
       " 'abundance tweekers crackheads amazing',\n",
       " 'abuse refill policy',\n",
       " 'abuse refill policy perfectly',\n",
       " 'abusing uhhh really',\n",
       " 'abusing uhhh really dude',\n",
       " 'accent fact iced',\n",
       " 'accent fact iced mocha',\n",
       " 'accent sounds much',\n",
       " 'accent sounds much like',\n",
       " 'accents vegas seriously',\n",
       " 'accents vegas seriously going',\n",
       " 'accept cards stupid',\n",
       " 'accept cards stupida',\n",
       " 'accept cards stupida mcdonald',\n",
       " 'accept cards time',\n",
       " 'accept cards time food',\n",
       " 'accept cash night',\n",
       " 'accept cash night sounds',\n",
       " 'accept find button',\n",
       " 'accept find button menu',\n",
       " 'accept kind service',\n",
       " 'accept kind service employees',\n",
       " 'accept lot promotional',\n",
       " 'accept lot promotional coupons',\n",
       " 'accept order guess',\n",
       " 'accept order guess thinks',\n",
       " 'acceptable please check',\n",
       " 'acceptable please check proof',\n",
       " 'acceptance credit cards',\n",
       " 'acceptance credit cards certain',\n",
       " 'accepted cash asked',\n",
       " 'accepted cash asked wanted',\n",
       " 'accepted credit dining',\n",
       " 'accepted credit late',\n",
       " 'accepted credit late night',\n",
       " 'accepted working give',\n",
       " 'accepted working give star',\n",
       " 'accepting cash going',\n",
       " 'accepting cash moment',\n",
       " 'accepting cash moment driver',\n",
       " 'accepting cash seems',\n",
       " 'accepting cash seems happen',\n",
       " 'accepting cash thing',\n",
       " 'accepting cash thing hour',\n",
       " 'accepting cash wanted',\n",
       " 'accepting cash wanted order',\n",
       " 'accepting food order',\n",
       " 'accepting food order taking',\n",
       " 'access drive thru',\n",
       " 'access drive thru window',\n",
       " 'access electric outlet',\n",
       " 'access electric outlet safe',\n",
       " 'access road back',\n",
       " 'access road back way',\n",
       " 'access roof top',\n",
       " 'access roof top bar',\n",
       " 'access wifi stopping',\n",
       " 'access wifi stopping mainly',\n",
       " 'accident ticket alley',\n",
       " 'accident ticket alley directly',\n",
       " 'accident trying leave',\n",
       " 'accident trying leave location',\n",
       " 'accidentally drilling hole',\n",
       " 'accidentally drilling hole first',\n",
       " 'accidentally gave cheeseburger',\n",
       " 'accidentally gave cheeseburger instead',\n",
       " 'accidentally happen emailed',\n",
       " 'accidentally happen emailed owner',\n",
       " 'accommodate circumstances guest',\n",
       " 'accommodate circumstances guest house',\n",
       " 'accommodate clientele nearby',\n",
       " 'accommodate clientele nearby observatory',\n",
       " 'accommodate customer something',\n",
       " 'accommodate customer something simple',\n",
       " 'accommodate customers temporary',\n",
       " 'accommodate customers temporary situation',\n",
       " 'accommodations offered mcd',\n",
       " 'accommodations offered mcd watched',\n",
       " 'accomplishes whether different',\n",
       " 'accomplishes whether different people',\n",
       " 'according cash wtf',\n",
       " 'according cash wtf crap',\n",
       " 'according cash yes',\n",
       " 'according cash yes yes',\n",
       " 'according experiences let',\n",
       " 'according experiences let begin',\n",
       " 'according order perhaps',\n",
       " 'according order perhaps tragedy',\n",
       " 'according statistical groupings',\n",
       " 'according statistical groupings wind',\n",
       " 'according super size',\n",
       " 'according super size heavy',\n",
       " 'according website include',\n",
       " 'according website include full',\n",
       " 'according wikipedia part',\n",
       " 'according wikipedia part world',\n",
       " 'accosted razor blade',\n",
       " 'accosted razor blade still',\n",
       " 'account chicken nuggets',\n",
       " 'account chicken nuggets fries',\n",
       " 'account mcdonald long',\n",
       " 'account mcdonald long drive',\n",
       " 'account weekend refund',\n",
       " 'account weekend refund went',\n",
       " 'account went back',\n",
       " 'account went back said',\n",
       " 'account within hours',\n",
       " 'account within hours days',\n",
       " 'accountability order correct',\n",
       " 'accountability order correct wonder',\n",
       " 'accountability waste property',\n",
       " 'accountability waste property cash',\n",
       " 'accountants elbowed way',\n",
       " 'accountants elbowed way kitchen',\n",
       " 'accoutrements must french',\n",
       " 'accoutrements must french cooking',\n",
       " 'accuracy bottom line',\n",
       " 'accuracy bottom line rather',\n",
       " 'accuracy laughing right',\n",
       " 'accuracy laughing right either',\n",
       " 'accuracy since challenge',\n",
       " 'accuracy since challenge much',\n",
       " 'accuracy soda cups',\n",
       " 'accuracy soda cups wiped',\n",
       " 'accuracy staff expressed',\n",
       " 'accuracy staff expressed willingness',\n",
       " 'accuracy sticker obviously',\n",
       " 'accuracy sticker obviously check',\n",
       " 'accurate coke always',\n",
       " 'accurate coke always mean',\n",
       " 'accurate numerous times',\n",
       " 'accurate numerous times sadly',\n",
       " 'accurate service friendly',\n",
       " 'accurate service friendly attentive',\n",
       " 'accurately orders waited',\n",
       " 'accurately orders waited minutes',\n",
       " 'accuse driving close',\n",
       " 'accuse driving close micky',\n",
       " 'accused lying said',\n",
       " 'accused lying said get',\n",
       " 'ache done place',\n",
       " 'ache done place need',\n",
       " 'ache may add',\n",
       " 'ache may add cashier',\n",
       " 'achieve perfection across',\n",
       " 'achieve perfection across franchise',\n",
       " 'acidity salted fries',\n",
       " 'acidity salted fries burger',\n",
       " 'acknowledge finally opened',\n",
       " 'acknowledge finally opened window',\n",
       " 'acknowledge obvious fact',\n",
       " 'acknowledge obvious fact work',\n",
       " 'acknowledged generosity took',\n",
       " 'acknowledged generosity took tray',\n",
       " 'acknowledged opened window',\n",
       " 'acknowledged opened window originally',\n",
       " 'acknowledges speaker menu',\n",
       " 'acknowledges speaker menu tonight',\n",
       " 'acknowledging usually employees',\n",
       " 'acknowledging usually employees slow',\n",
       " 'acres market table',\n",
       " 'acres market table essentially',\n",
       " 'across bridge probably',\n",
       " 'across bridge probably crap',\n",
       " 'across bridge tried',\n",
       " 'across bridge tried give',\n",
       " 'across counter walks',\n",
       " 'across counter walks away',\n",
       " 'across dining room',\n",
       " 'across dining room turn',\n",
       " 'across encourages mcdonald',\n",
       " 'across food court',\n",
       " 'across food court tried',\n",
       " 'across footbridge new',\n",
       " 'across footbridge new york',\n",
       " 'across franchise much',\n",
       " 'across franchise much laudable',\n",
       " 'across fry salt',\n",
       " 'across fry salt residue',\n",
       " 'across get right',\n",
       " 'across get right time',\n",
       " 'across gob congealed',\n",
       " 'across gob congealed milk',\n",
       " 'across kitchen loudly',\n",
       " 'across kitchen loudly obnoxiously',\n",
       " 'across lanes get',\n",
       " 'across lanes get usuals',\n",
       " 'across length bun',\n",
       " 'across length bun sure',\n",
       " 'across locations however',\n",
       " 'across locations however location',\n",
       " 'across miami dade',\n",
       " 'across miami dade college',\n",
       " 'across nation like',\n",
       " 'across nation like coffee',\n",
       " 'across parking lot',\n",
       " 'across parking lot kind',\n",
       " 'across parking unfortunately',\n",
       " 'across parking unfortunately normally',\n",
       " 'across place coffee',\n",
       " 'across place coffee usually',\n",
       " 'across restaurant paying',\n",
       " 'across restaurant paying homage',\n",
       " 'across sahara design',\n",
       " 'across sahara design like',\n",
       " 'across sls day',\n",
       " 'across sls day visit',\n",
       " 'across starts making',\n",
       " 'across starts making conversation',\n",
       " 'across street aaaaaaaahhhhhhhhhhh',\n",
       " 'across street aaaaaaaahhhhhhhhhhh still',\n",
       " 'across street always',\n",
       " 'across street always waste',\n",
       " 'across street apartment',\n",
       " 'across street apartment witnessing',\n",
       " 'across street definitely',\n",
       " 'across street definitely linger',\n",
       " 'across street forget',\n",
       " 'across street forget tip',\n",
       " 'across street get',\n",
       " 'across street get day',\n",
       " 'across street historic',\n",
       " 'across street historic building',\n",
       " 'across street house',\n",
       " 'across street house around',\n",
       " 'across street little',\n",
       " 'across street little wonder',\n",
       " 'across street mcdonald',\n",
       " 'across street mcdonald used',\n",
       " 'across street office',\n",
       " 'across street office craving',\n",
       " 'across street probably',\n",
       " 'across street probably going',\n",
       " 'across street refuse',\n",
       " 'across street refuse stop',\n",
       " 'across street restaurant',\n",
       " 'across street restaurant filled',\n",
       " 'across street surprised',\n",
       " 'across street surprised see',\n",
       " 'across street usually',\n",
       " 'across street usually burn',\n",
       " 'across street whopper',\n",
       " 'across street whopper king',\n",
       " 'across street zombies',\n",
       " 'across street zombies appeared',\n",
       " 'across three different',\n",
       " 'across three different cities',\n",
       " 'across university miami',\n",
       " 'across university miami hub',\n",
       " 'across usually line',\n",
       " 'across usually line drive',\n",
       " 'across window guy',\n",
       " 'across window guy always',\n",
       " 'act applies people',\n",
       " 'act applies people born',\n",
       " 'act beyond world',\n",
       " 'act beyond world many',\n",
       " 'act like bothering',\n",
       " 'act like bothering drive',\n",
       " 'act like fight',\n",
       " 'act like fight seriously',\n",
       " 'act like hanging',\n",
       " 'act like hanging street',\n",
       " 'act like idea',\n",
       " 'act like idea talking',\n",
       " 'act like rant',\n",
       " 'act like rant fries',\n",
       " 'act like taking',\n",
       " 'act like taking order',\n",
       " 'act like wears',\n",
       " 'act like wears pants',\n",
       " 'act way back',\n",
       " 'act way back hiking',\n",
       " 'acted bothered asked',\n",
       " 'acted bothered asked begrudgingly',\n",
       " 'acted burdening maybe',\n",
       " 'acted burdening maybe expecting',\n",
       " 'acted like bothering',\n",
       " 'acted like bothering occasionally',\n",
       " 'acted like else',\n",
       " 'acted like else get',\n",
       " 'acted like fault',\n",
       " 'acted like fault refunded',\n",
       " 'acted like making',\n",
       " 'acted like making far',\n",
       " 'acted like physically',\n",
       " 'acted like physically painful',\n",
       " 'acting damn mess',\n",
       " 'acting damn mess sitting',\n",
       " 'acting like nothings',\n",
       " 'acting like nothings wrong',\n",
       " 'acting like worse',\n",
       " 'acting like worse part',\n",
       " 'acting still high',\n",
       " 'acting still high school',\n",
       " 'acting stupid like',\n",
       " 'acting stupid like idea',\n",
       " 'acting though territory',\n",
       " 'acting though territory lining',\n",
       " 'action decided time',\n",
       " 'action decided time change',\n",
       " 'actions went get',\n",
       " 'actions went get soda',\n",
       " 'active might add',\n",
       " 'active might add bet',\n",
       " 'active problems knows',\n",
       " 'active problems knows whether',\n",
       " 'actively working either',\n",
       " 'actively working either completing',\n",
       " 'activists run establishment',\n",
       " 'activists run establishment asked',\n",
       " 'activities little guys',\n",
       " 'activities little guys small',\n",
       " 'activity inside enough',\n",
       " 'activity inside enough workers',\n",
       " 'activity lately including',\n",
       " 'activity lately including arrest',\n",
       " 'acts though big',\n",
       " 'acts though big favor',\n",
       " 'actual bag called',\n",
       " 'actual bag called talk',\n",
       " 'actual coffee thing',\n",
       " 'actual coffee thing mean',\n",
       " 'actual dairy things',\n",
       " 'actual dairy things think',\n",
       " 'actual food cooked',\n",
       " 'actual food cooked getting',\n",
       " 'actual food service',\n",
       " 'actual food service although',\n",
       " 'actual human dealing',\n",
       " 'actual human dealing mcd',\n",
       " 'actual manager waited',\n",
       " 'actual manager waited said',\n",
       " 'actual meal fond',\n",
       " 'actual meal fond memories',\n",
       " 'actual orders order',\n",
       " 'actual orders order incorrect',\n",
       " 'actual person place',\n",
       " 'actual person place drive',\n",
       " 'actual place seem',\n",
       " 'actual place seem improve',\n",
       " 'actual work obvious',\n",
       " 'actual work obvious attitude',\n",
       " 'actually answered told',\n",
       " 'actually answered told happened',\n",
       " 'actually ask someone',\n",
       " 'actually ask someone trashcan',\n",
       " 'actually bag got',\n",
       " 'actually bag got home',\n",
       " 'actually brandon worked',\n",
       " 'actually brandon worked mcd',\n",
       " 'actually checks back',\n",
       " 'actually checks back card',\n",
       " 'actually cook food',\n",
       " 'actually cook food cook',\n",
       " 'actually cut front',\n",
       " 'actually cut front line',\n",
       " 'actually deal lot',\n",
       " 'actually deal lot problematic',\n",
       " 'actually delivered surprise',\n",
       " 'actually delivered surprise hope',\n",
       " 'actually drive thru',\n",
       " 'actually drive thru moves',\n",
       " 'actually eat mcdonalds',\n",
       " 'actually eat mcdonalds choose',\n",
       " 'actually egg mcmuffin',\n",
       " 'actually egg mcmuffin absolutely',\n",
       " 'actually enjoy eating',\n",
       " 'actually enjoy eating mcdonald',\n",
       " 'actually far would',\n",
       " 'actually far would normally',\n",
       " 'actually feel bit',\n",
       " 'actually feel bit sorry',\n",
       " 'actually felt like',\n",
       " 'actually felt like mcdonald',\n",
       " 'actually friendly dynamic',\n",
       " 'actually friendly dynamic awkward',\n",
       " 'actually gave someone',\n",
       " 'actually gave someone else',\n",
       " 'actually get crap',\n",
       " 'actually get crap food',\n",
       " 'actually get order',\n",
       " 'actually get order right',\n",
       " 'actually getting turn',\n",
       " 'actually getting turn indulge',\n",
       " 'actually give always',\n",
       " 'actually give always obviously',\n",
       " 'actually got accident',\n",
       " 'actually got accident trying',\n",
       " 'actually got food',\n",
       " 'actually got food pretty',\n",
       " 'actually handed separate',\n",
       " 'actually handed separate cup',\n",
       " 'actually hate location',\n",
       " 'actually hate location closest',\n",
       " 'actually inside drive',\n",
       " 'actually inside drive thru',\n",
       " 'actually inside fast',\n",
       " 'actually inside fast food',\n",
       " 'actually inside years',\n",
       " 'actually inside years seen',\n",
       " 'actually jobs sure',\n",
       " 'actually jobs sure cant',\n",
       " 'actually left cause',\n",
       " 'actually left cause think',\n",
       " 'actually left threw',\n",
       " 'actually left threw mcdonald',\n",
       " 'actually like melted',\n",
       " 'actually like melted andes',\n",
       " 'actually longer ordering',\n",
       " 'actually longer ordering inside',\n",
       " 'actually looked disgusting',\n",
       " 'actually looked disgusting fries',\n",
       " 'actually looked like',\n",
       " 'actually looked like happy',\n",
       " 'actually looked really',\n",
       " 'actually looked really neat',\n",
       " 'actually looks like',\n",
       " 'actually looks like item',\n",
       " 'actually lukewarm best',\n",
       " 'actually lukewarm best drove',\n",
       " 'actually made coffee',\n",
       " 'actually made coffee quickly',\n",
       " 'actually make fresh',\n",
       " 'actually make fresh thanks',\n",
       " 'actually manager came',\n",
       " 'actually manager came two',\n",
       " 'actually manager personality',\n",
       " 'actually manager personality rock',\n",
       " 'actually means barbeque',\n",
       " 'actually means barbeque stopped',\n",
       " 'actually nicer interiors',\n",
       " 'actually nicer interiors mcdonalds',\n",
       " 'actually nicer mcds',\n",
       " 'actually nicer mcds mcdonalds',\n",
       " 'actually order little',\n",
       " 'actually order little longer',\n",
       " 'actually ordered samantha',\n",
       " 'actually ordered samantha took',\n",
       " 'actually paid ugh',\n",
       " 'actually paid ugh hope',\n",
       " 'actually personal space',\n",
       " 'actually personal space homeless',\n",
       " 'actually pretty big',\n",
       " 'actually pretty big kept',\n",
       " 'actually pretty busy',\n",
       " 'actually pretty busy quite',\n",
       " 'actually pretty nice',\n",
       " 'actually pretty nice never',\n",
       " 'actually pretty tasty',\n",
       " 'actually pretty tasty impressed',\n",
       " 'actually pretty tasty love',\n",
       " 'actually purchased anything',\n",
       " 'actually purchased anything mcdonalds',\n",
       " 'actually put effort',\n",
       " 'actually put effort messing',\n",
       " 'actually quite generous',\n",
       " 'actually quite generous people',\n",
       " 'actually quite good',\n",
       " 'actually quite nice',\n",
       " 'actually quite nice compare',\n",
       " 'actually rather bum',\n",
       " 'actually rather bum infested',\n",
       " 'actually really clean',\n",
       " 'actually really clean surprising',\n",
       " 'actually record anything',\n",
       " 'actually record anything youtube',\n",
       " 'actually removed pieces',\n",
       " 'actually removed pieces brother',\n",
       " 'actually responded complaint',\n",
       " 'actually responded complaint letter',\n",
       " 'actually reviewing mcdonalds',\n",
       " 'actually reviewing mcdonalds came',\n",
       " 'actually sat trapped',\n",
       " 'actually sat trapped drive',\n",
       " 'actually service kindness',\n",
       " 'actually service kindness possibly',\n",
       " 'actually shown dateline',\n",
       " 'actually shown dateline shows',\n",
       " 'actually smile seem',\n",
       " 'actually smile seem truly',\n",
       " 'actually something usually',\n",
       " 'actually something usually location',\n",
       " 'actually staff move',\n",
       " 'actually staff move like',\n",
       " 'actually stop customers',\n",
       " 'actually stop customers mid',\n",
       " 'actually store manager',\n",
       " 'actually store manager completely',\n",
       " 'actually tastes good',\n",
       " 'actually tastes good like',\n",
       " 'actually tell see',\n",
       " 'actually tell see chicken',\n",
       " 'actually testament strong',\n",
       " 'actually testament strong mcdonalds',\n",
       " 'actually think conveniently',\n",
       " 'actually think conveniently located',\n",
       " 'actually throw away',\n",
       " 'actually throw away love',\n",
       " 'actually tried shove',\n",
       " 'actually tried shove drive',\n",
       " 'actually try improve',\n",
       " 'actually try improve service',\n",
       " 'actually two boyfriend',\n",
       " 'actually two boyfriend ordered',\n",
       " 'actually two reasons',\n",
       " 'actually two reasons moniker',\n",
       " 'actually used stop',\n",
       " 'actually used stop pretty',\n",
       " 'actually wait line',\n",
       " 'actually wait line matter',\n",
       " 'actually warm smile',\n",
       " 'actually warm smile unexpected',\n",
       " 'actually watched manager',\n",
       " 'actually watched manager treated',\n",
       " 'actually went inside',\n",
       " 'actually went inside complain',\n",
       " 'actually wiped table',\n",
       " 'actually wiped table clean',\n",
       " 'actually work order',\n",
       " 'actually work order order',\n",
       " 'actually work shame',\n",
       " 'actually work shame get',\n",
       " 'actually workz drive',\n",
       " 'actually workz drive thru',\n",
       " 'actually yelled takes',\n",
       " 'actually yelled takes orders',\n",
       " 'add another drive',\n",
       " 'add another drive lane',\n",
       " 'add apple pie',\n",
       " 'add apple pie please',\n",
       " 'add bacon breakfast',\n",
       " 'add bacon breakfast sandwich',\n",
       " 'add bacon burger',\n",
       " 'add bacon burger get',\n",
       " 'add bacon charge',\n",
       " 'add bacon charge piece',\n",
       " 'add bet balance',\n",
       " 'add bet balance missing',\n",
       " 'add big mac',\n",
       " 'add big mac sauce',\n",
       " 'add bit hands',\n",
       " 'add bit hands back',\n",
       " 'add book kids',\n",
       " 'add book kids breakfast',\n",
       " 'add cashier mgr',\n",
       " 'add cashier mgr shirt',\n",
       " 'add coffee believe',\n",
       " 'add coffee believe coffee',\n",
       " 'add dozens homeless',\n",
       " 'add dozens homeless people',\n",
       " 'add friend sip',\n",
       " 'add friend sip sweet',\n",
       " 'add insult injury',\n",
       " 'add insult injury got',\n",
       " 'add mayo mustard',\n",
       " 'add mayo mustard onions',\n",
       " 'add meat yeah',\n",
       " 'add meat yeah point',\n",
       " 'add mixtures filler',\n",
       " 'add mixtures filler flavor',\n",
       " 'add much sugar',\n",
       " 'add much sugar spike',\n",
       " 'add mustard kept',\n",
       " 'add mustard kept asking',\n",
       " 'add onion burger',\n",
       " 'add onion burger never',\n",
       " 'add order computer',\n",
       " 'add order computer people',\n",
       " 'add pickles got',\n",
       " 'add pickles got cheese',\n",
       " 'add review mcdonald',\n",
       " 'add review mcdonald checks',\n",
       " 'add rude tone',\n",
       " 'add rude tone attitude',\n",
       " 'add salt fries',\n",
       " 'add salt fries today',\n",
       " 'add shredded lettuce',\n",
       " 'add shredded lettuce grilled',\n",
       " 'add spill clothes',\n",
       " 'add spill clothes since',\n",
       " 'add spite fact',\n",
       " 'add spite fact neon',\n",
       " 'add told wait',\n",
       " 'add told wait cook',\n",
       " 'add usual ambiance',\n",
       " 'add usual ambiance dirty',\n",
       " 'added asked smiled',\n",
       " 'added asked smiled said',\n",
       " 'added drink work',\n",
       " 'added drink work clothes',\n",
       " 'added even specifically',\n",
       " 'added even specifically ask',\n",
       " 'added hash brown',\n",
       " 'added hash brown luckily',\n",
       " 'added ice cream',\n",
       " 'added ice cream cousin',\n",
       " 'added items dollar',\n",
       " 'added items dollar menu',\n",
       " 'added last winter',\n",
       " 'added last winter saw',\n",
       " 'added mayonaise need',\n",
       " 'added mayonaise need tell',\n",
       " 'added pieces sauces',\n",
       " 'added pieces sauces special',\n",
       " 'added smoothies great',\n",
       " 'added smoothies great disappointed',\n",
       " 'added star staff',\n",
       " 'added star staff problem',\n",
       " 'addict else get',\n",
       " 'addict else get reasonably',\n",
       " 'addiction location provided',\n",
       " 'addiction location provided extra',\n",
       " 'addictive chemical flavorings',\n",
       " 'addictive chemical flavorings make',\n",
       " 'addicts asking money',\n",
       " 'addicts asking money times',\n",
       " 'addicts criminals times',\n",
       " 'addicts criminals times went',\n",
       " 'adding sugar unacceptable',\n",
       " 'adding sugar unacceptable drive',\n",
       " 'addional tips asks',\n",
       " 'addional tips asks said',\n",
       " 'addison super packed',\n",
       " 'addison super packed comparison',\n",
       " 'addition cashier hard',\n",
       " 'addition cashier hard time',\n",
       " 'addition first delays',\n",
       " 'addition first delays eat',\n",
       " 'addition gone lunch',\n",
       " 'addition gone lunch meat',\n",
       " 'addition incorrect order',\n",
       " 'addition incorrect order order',\n",
       " 'addition regular relatively',\n",
       " 'addition regular relatively old',\n",
       " 'addition second drive',\n",
       " 'addition second drive thru',\n",
       " 'additional bucks normal',\n",
       " 'additional bucks normal price',\n",
       " 'additional cheeseburgers manager',\n",
       " 'additional cheeseburgers manager tells',\n",
       " 'additional moments clearly',\n",
       " 'additional moments clearly meal',\n",
       " 'additional packet ketchup',\n",
       " 'additional packet ketchup might',\n",
       " 'additional packet tray',\n",
       " 'additional packet tray sign',\n",
       " 'additional waiting areas',\n",
       " 'additional waiting areas people',\n",
       " 'additionally mcdonald went',\n",
       " 'additionally mcdonald went drive',\n",
       " 'additionally overheard called',\n",
       " 'additionally overheard called word',\n",
       " 'additionally store honor',\n",
       " 'additionally store honor coupons',\n",
       " 'address everyone store',\n",
       " 'address everyone store long',\n",
       " 'address issues without',\n",
       " 'address issues without completely',\n",
       " 'address phone number',\n",
       " 'address phone number towing',\n",
       " 'address previous reviews',\n",
       " 'address previous reviews regarding',\n",
       " 'address someplace headed',\n",
       " 'address someplace headed took',\n",
       " 'addressing went backed',\n",
       " 'addressing went backed away',\n",
       " 'adds subtracts something',\n",
       " 'adds subtracts something order',\n",
       " 'adequate hour laundromat',\n",
       " 'adequate hour laundromat next',\n",
       " 'adequate staff hand',\n",
       " 'adequate staff hand moved',\n",
       " 'adhere corporate protocol',\n",
       " 'adhere corporate protocol customer',\n",
       " 'adheres sense time',\n",
       " 'adheres sense time service',\n",
       " 'adjacent albertsons parking',\n",
       " 'adjacent albertsons parking lot',\n",
       " 'adjacent buildings property',\n",
       " 'adjacent buildings property values',\n",
       " 'adjacent chick fil',\n",
       " 'adjacent chick fil open',\n",
       " 'adjacent former kmart',\n",
       " 'adjacent former kmart good',\n",
       " 'adjacent honda dealership',\n",
       " 'adjacent honda dealership around',\n",
       " 'adjacent large soccer',\n",
       " 'adjacent large soccer field',\n",
       " 'adjacent neighborhoods sports',\n",
       " 'adjacent neighborhoods sports teams',\n",
       " 'adjacent panchito yelp',\n",
       " 'adjacent panchito yelp panchitos',\n",
       " 'adjust order according',\n",
       " 'adjust order according cash',\n",
       " 'adjustment since time',\n",
       " 'adjustment since time last',\n",
       " 'admire surroundings order',\n",
       " 'admire surroundings order everything',\n",
       " 'admit big fan',\n",
       " 'admit big fan mcdonald',\n",
       " 'admit delicious cinnamon',\n",
       " 'admit delicious cinnamon buns',\n",
       " 'admit dollar menu',\n",
       " 'admit dollar menu addict',\n",
       " 'admit donald great',\n",
       " 'admit donald great history',\n",
       " 'admit eat mcdonalds',\n",
       " 'admit eat mcdonalds pretty',\n",
       " 'admit every get',\n",
       " 'admit every get bic',\n",
       " 'admit fan fast',\n",
       " 'admit fan fast food',\n",
       " 'admit former starting',\n",
       " 'admit former starting become',\n",
       " 'admit frequent mcdonald',\n",
       " 'admit frequent mcdonald least',\n",
       " 'admit guilty came',\n",
       " 'admit guilty came times',\n",
       " 'admit keep coming',\n",
       " 'admit keep coming back',\n",
       " 'admit like two',\n",
       " 'admit like two times',\n",
       " 'admit lot food',\n",
       " 'admit lot food small',\n",
       " 'admit notice give',\n",
       " 'admit notice give coffee',\n",
       " 'admit paid attention',\n",
       " 'admit paid attention fight',\n",
       " 'admit proximity greyhound',\n",
       " 'admit proximity greyhound station',\n",
       " 'admit sometimes horrible',\n",
       " 'admit sometimes horrible parking',\n",
       " 'admit stop every',\n",
       " 'admit stop every often',\n",
       " 'admittedly unruly customer',\n",
       " 'admittedly unruly customer sweet',\n",
       " 'adolescents give crap',\n",
       " 'adolescents give crap back',\n",
       " 'ads new chipotle',\n",
       " 'ads new chipotle bbq',\n",
       " 'ads work resist',\n",
       " 'ads work resist extra',\n",
       " 'adult consumes better',\n",
       " 'adult consumes better mcds',\n",
       " 'adult hate experience',\n",
       " 'adult hate experience location',\n",
       " 'adults frantically searching',\n",
       " 'adults frantically searching kid',\n",
       " 'adults freely walking',\n",
       " 'adults freely walking would',\n",
       " 'adults whole place',\n",
       " 'adults whole place kids',\n",
       " 'advance join main',\n",
       " 'advance join main paying',\n",
       " 'advance nuked upon',\n",
       " 'advance nuked upon order',\n",
       " 'advantage economies scale',\n",
       " 'advantage economies scale purchasing',\n",
       " 'advantage right new',\n",
       " 'advantage right new yorker',\n",
       " 'advantageous light snack',\n",
       " 'advantageous light snack large',\n",
       " 'adventure def regulars',\n",
       " 'adventure def regulars set',\n",
       " 'advertise coffee much',\n",
       " 'advertise coffee much sorts',\n",
       " 'advertise drive thru',\n",
       " 'advertise drive thru open',\n",
       " 'advertised breakfast menus',\n",
       " 'advertised breakfast menus size',\n",
       " 'advertised hour drive',\n",
       " 'advertised hour drive thru',\n",
       " 'advertised mcdonalds often',\n",
       " 'advertised mcdonalds often working',\n",
       " 'advertised price large',\n",
       " 'advertised price large iced',\n",
       " 'advertisements hearing years',\n",
       " 'advertisements hearing years pitching',\n",
       " 'advertisements often include',\n",
       " 'advertisements often include participation',\n",
       " 'advertising law seem',\n",
       " 'advertising law seem press',\n",
       " 'advertising let say',\n",
       " 'advertising let say taking',\n",
       " 'advice listen closely',\n",
       " 'advice listen closely numbers',\n",
       " 'advice locations run',\n",
       " 'advice locations run business',\n",
       " 'advice makes much',\n",
       " 'advice makes much sense',\n",
       " 'advice took advantage',\n",
       " 'advice took advantage right',\n",
       " 'advice witness depressed',\n",
       " 'advice witness depressed people',\n",
       " 'advised get mocha',\n",
       " 'advised get mocha asked',\n",
       " 'advocate going mcdonald',\n",
       " 'advocate going mcdonald fillet',\n",
       " 'afb never great',\n",
       " 'afb never great customer',\n",
       " 'affixing animals way',\n",
       " 'affixing animals way would',\n",
       " 'affluent solon shocking',\n",
       " 'affluent solon shocking surprise',\n",
       " 'afford double cheeseburger',\n",
       " 'afford double cheeseburger get',\n",
       " 'afford drink fire',\n",
       " 'afford drink fire hole',\n",
       " 'afford single pleasure',\n",
       " 'afford single pleasure meaningless',\n",
       " 'afford something else',\n",
       " 'afford something else enjoy',\n",
       " 'affordable even dollar',\n",
       " 'affordable even dollar menu',\n",
       " 'affordable rest putting',\n",
       " 'affordable rest putting feet',\n",
       " 'afghanistan watch new',\n",
       " 'afghanistan watch new york',\n",
       " 'aforementioned payroll conversation',\n",
       " 'aforementioned payroll conversation finally',\n",
       " 'afraid afraid costumer',\n",
       " 'afraid afraid costumer service',\n",
       " 'afraid costumer service',\n",
       " 'afraid costumer service sucks',\n",
       " 'afraid people rge',\n",
       " 'afraid people rge way',\n",
       " 'african american attendant',\n",
       " 'african american attendant seen',\n",
       " 'african american working',\n",
       " 'african american working drive',\n",
       " 'afro think manager',\n",
       " 'afterall mcdonald within',\n",
       " 'afterall mcdonald within couple',\n",
       " 'aftering stating spanish',\n",
       " 'aftering stating spanish wanted',\n",
       " 'afternoon dipped cones',\n",
       " 'afternoon dipped cones know',\n",
       " 'afternoon drive backed',\n",
       " 'afternoon drive backed manager',\n",
       " 'afternoon friends told',\n",
       " 'afternoon friends told carbonated',\n",
       " 'afternoon moderately busy',\n",
       " 'afternoon moderately busy cashier',\n",
       " 'afternoon order show',\n",
       " 'afternoon order show correct',\n",
       " 'afternoon pretty empty',\n",
       " 'afternoon pretty empty loud',\n",
       " 'afternoon probably two',\n",
       " 'afternoon probably two cars',\n",
       " 'afternoon says icecream',\n",
       " 'afternoon says icecream machine',\n",
       " 'afternoon sitting living',\n",
       " 'afternoon sitting living room',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T04:20:34.481382Z",
     "start_time": "2021-03-31T04:20:34.430518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1515</th>\n",
       "      <th>1516</th>\n",
       "      <th>1517</th>\n",
       "      <th>1518</th>\n",
       "      <th>1519</th>\n",
       "      <th>1520</th>\n",
       "      <th>1521</th>\n",
       "      <th>1522</th>\n",
       "      <th>1523</th>\n",
       "      <th>1524</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaaaaaaahhhhhhhhhhh still feel</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaaaaahhhhhhhhhhh still feel situation</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbreviated menu worthy</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbreviated menu worthy mcdonald</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abc kitchen numerous</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombies bikes stopped stare</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombies little less</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombies little less predictable</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoom line person</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoom line person waving</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126454 rows × 1525 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          0     1     2     3     4     5     \\\n",
       "aaaaaaaahhhhhhhhhhh still feel             0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "aaaaaaaahhhhhhhhhhh still feel situation   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "abbreviated menu worthy                    0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "abbreviated menu worthy mcdonald           0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "abc kitchen numerous                       0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "...                                        ...   ...   ...   ...   ...   ...   \n",
       "zombies bikes stopped stare                0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "zombies little less                        0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "zombies little less predictable            0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "zoom line person                           0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "zoom line person waving                    0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "                                          6     7     8     9     ...  1515  \\\n",
       "aaaaaaaahhhhhhhhhhh still feel             0.0   0.0   0.0   0.0  ...   0.0   \n",
       "aaaaaaaahhhhhhhhhhh still feel situation   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "abbreviated menu worthy                    0.0   0.0   0.0   0.0  ...   0.0   \n",
       "abbreviated menu worthy mcdonald           0.0   0.0   0.0   0.0  ...   0.0   \n",
       "abc kitchen numerous                       0.0   0.0   0.0   0.0  ...   0.0   \n",
       "...                                        ...   ...   ...   ...  ...   ...   \n",
       "zombies bikes stopped stare                0.0   0.0   0.0   0.0  ...   0.0   \n",
       "zombies little less                        0.0   0.0   0.0   0.0  ...   0.0   \n",
       "zombies little less predictable            0.0   0.0   0.0   0.0  ...   0.0   \n",
       "zoom line person                           0.0   0.0   0.0   0.0  ...   0.0   \n",
       "zoom line person waving                    0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "                                          1516  1517  1518  1519  1520  1521  \\\n",
       "aaaaaaaahhhhhhhhhhh still feel             0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "aaaaaaaahhhhhhhhhhh still feel situation   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "abbreviated menu worthy                    0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "abbreviated menu worthy mcdonald           0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "abc kitchen numerous                       0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "...                                        ...   ...   ...   ...   ...   ...   \n",
       "zombies bikes stopped stare                0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "zombies little less                        0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "zombies little less predictable            0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "zoom line person                           0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "zoom line person waving                    0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "                                          1522  1523  1524  \n",
       "aaaaaaaahhhhhhhhhhh still feel             0.0   0.0   0.0  \n",
       "aaaaaaaahhhhhhhhhhh still feel situation   0.0   0.0   0.0  \n",
       "abbreviated menu worthy                    0.0   0.0   0.0  \n",
       "abbreviated menu worthy mcdonald           0.0   0.0   0.0  \n",
       "abc kitchen numerous                       0.0   0.0   0.0  \n",
       "...                                        ...   ...   ...  \n",
       "zombies bikes stopped stare                0.0   0.0   0.0  \n",
       "zombies little less                        0.0   0.0   0.0  \n",
       "zombies little less predictable            0.0   0.0   0.0  \n",
       "zoom line person                           0.0   0.0   0.0  \n",
       "zoom line person waving                    0.0   0.0   0.0  \n",
       "\n",
       "[126454 rows x 1525 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T04:22:07.028450Z",
     "start_time": "2021-03-31T04:22:03.960459Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T04:22:13.509763Z",
     "start_time": "2021-03-31T04:22:13.485799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>worst mcdonald ever</th>\n",
       "      <td>2.602793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get order right</th>\n",
       "      <td>2.390093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst mcdonalds ever</th>\n",
       "      <td>2.342385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>went drive thru</th>\n",
       "      <td>1.754710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drive thru window</th>\n",
       "      <td>1.624240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need let peeps yelper</th>\n",
       "      <td>0.033990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>part mcwrap could</th>\n",
       "      <td>0.033990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much stinky yes stinky</th>\n",
       "      <td>0.033990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much stinky yes</th>\n",
       "      <td>0.033990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peeking top looking</th>\n",
       "      <td>0.033990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126454 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           score\n",
       "worst mcdonald ever     2.602793\n",
       "get order right         2.390093\n",
       "worst mcdonalds ever    2.342385\n",
       "went drive thru         1.754710\n",
       "drive thru window       1.624240\n",
       "...                          ...\n",
       "need let peeps yelper   0.033990\n",
       "part mcwrap could       0.033990\n",
       "much stinky yes stinky  0.033990\n",
       "much stinky yes         0.033990\n",
       "peeking top looking     0.033990\n",
       "\n",
       "[126454 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score\n",
    "# used to summarize the meaning of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.to_csv(\"scores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "For the following exercises, use the definitions below:\n",
    "\n",
    "**Term frequency**:\n",
    "$$\n",
    "tf = n(t,d)\n",
    "$$\n",
    "**Inverse document frequency**:\n",
    "$$\n",
    "idf = 1 + \\frac{N}{df(t) + 1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"He ate the food\",\n",
    "    \"He liked the meal\",\n",
    "    \"She likes the food from McDonalds, but she avoids the food from Burger King\",\n",
    "    \"They like to eat 3 meals a day\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the TF-IDF score for `like` in each of the documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the TF-IDF score for `the food` bigram in each of the documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
